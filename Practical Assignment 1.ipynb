{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chipojaya1/Machine-Learning-I/blob/main/Practical%20Assignment%201.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **DNSC6314 Assignment 1 by Chipo Jaya: G44454879**"
      ],
      "metadata": {
        "id": "j__1ZiLtX1Ju"
      },
      "id": "j__1ZiLtX1Ju"
    },
    {
      "cell_type": "markdown",
      "id": "55a91441",
      "metadata": {
        "id": "55a91441"
      },
      "source": [
        "## This assignment uses Capital Bikeshare Data\n",
        "https://ride.capitalbikeshare.com/system-data\n",
        "\n",
        "Data is from three months: 2024/02, 2024/03 and 2024/04."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Getting started"
      ],
      "metadata": {
        "id": "L8IW9x_5YGkj"
      },
      "id": "L8IW9x_5YGkj"
    },
    {
      "cell_type": "code",
      "source": [
        "# mount google drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "z6PSK4jES9P1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c6a46653-4e07-4b3a-dbdf-da0f9244f0a4"
      },
      "id": "z6PSK4jES9P1",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# cloning github repository to access data\n",
        "!git clone https://github.com/chipojaya1/Machine-Learning-I.git"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SkZxdkCFkOL",
        "outputId": "48ce703c-bc99-475c-b320-e8c4933c1e09"
      },
      "id": "0SkZxdkCFkOL",
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Machine-Learning-I'...\n",
            "fatal: could not read Username for 'https://github.com': No such device or address\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# for feature engineering\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error"
      ],
      "metadata": {
        "id": "er1h90lVsNCf"
      },
      "id": "er1h90lVsNCf",
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.set(style='whitegrid')     # Set visual style for seaborn"
      ],
      "metadata": {
        "id": "4ktI0lv5sL-X"
      },
      "id": "4ktI0lv5sL-X",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the data\n",
        "df_Feb = pd.read_csv('202402-capitalbikeshare-tripdata.csv')\n",
        "df_Mar = pd.read_csv('202403-capitalbikeshare-tripdata.csv')\n",
        "df_Apr = pd.read_csv('202404-capitalbikeshare-tripdata.csv')\n",
        "\n",
        "# concat data\n",
        "df_bike=pd.concat([df_Feb, df_Mar,df_Apr])"
      ],
      "metadata": {
        "id": "X4MzX_C0WHiq"
      },
      "id": "X4MzX_C0WHiq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bike.shape"
      ],
      "metadata": {
        "id": "ArlHLZxhGYJW"
      },
      "id": "ArlHLZxhGYJW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bike.head()"
      ],
      "metadata": {
        "id": "c4387QeZVhRb"
      },
      "id": "c4387QeZVhRb",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_bike.info()"
      ],
      "metadata": {
        "id": "8-sY4iV8XoNK"
      },
      "id": "8-sY4iV8XoNK",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Focusing on the GWSB Station: '22nd & H St NW'"
      ],
      "metadata": {
        "id": "aVqYNoxrcbyD"
      },
      "id": "aVqYNoxrcbyD"
    },
    {
      "cell_type": "markdown",
      "id": "1520a1db",
      "metadata": {
        "id": "1520a1db"
      },
      "source": [
        "### Bike Availability: Number of Pickups"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'started_at' column to datetime objects\n",
        "df_bike['started_at_date'] = pd.to_datetime(df_bike['started_at']).dt.date\n",
        "\n",
        "# Filter for trips started at '22nd & H St NW'\n",
        "PU_trips = df_bike[df_bike['start_station_name'] == '22nd & H St NW']\n",
        "\n",
        "# Group by date and count the trips\n",
        "PU_counts = PU_trips.groupby('started_at_date')['started_at_date'].count()\n",
        "\n",
        "PU_counts"
      ],
      "metadata": {
        "id": "y3VxzXhcZn-k"
      },
      "id": "y3VxzXhcZn-k",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dock Availability: Number of Dropoffs"
      ],
      "metadata": {
        "id": "NMY1dXxqdAPt"
      },
      "id": "NMY1dXxqdAPt"
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'ended_at' column to datetime objects\n",
        "df_bike['ended_at_date'] = pd.to_datetime(df_bike['ended_at']).dt.date\n",
        "\n",
        "# Filter for trips ended at '22nd & H St NW'\n",
        "DO_trips = df_bike[df_bike['end_station_name'] == '22nd & H St NW']\n",
        "\n",
        "# Group by date and count the trips\n",
        "DO_counts = DO_trips.groupby('ended_at_date')['ended_at_date'].count()\n",
        "\n",
        "DO_counts"
      ],
      "metadata": {
        "id": "SRtAGqpCc_Wj"
      },
      "id": "SRtAGqpCc_Wj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Merging Pick Up and Drop Off tables\n",
        "- For each day, we look at the numbers of pickups and dropoffs"
      ],
      "metadata": {
        "id": "3qosEW4wdVJ2"
      },
      "id": "3qosEW4wdVJ2"
    },
    {
      "cell_type": "code",
      "source": [
        "# merge PU_counts and DO_counts by matching the dates, and change the column names to PU_count and DO_count respectively.\n",
        "\n",
        "PU_DO_counts = pd.merge(PU_counts, DO_counts, left_index=True, right_index=True, how='outer')\n",
        "PU_DO_counts = PU_DO_counts.rename(columns={'started_at_date': 'PU_ct', 'ended_at_date': 'DO_ct'})\n",
        "\n",
        "# change the index name from 'started_at' to 'date'\n",
        "\n",
        "PU_DO_counts = PU_DO_counts.rename_axis('date')\n",
        "PU_DO_counts\n"
      ],
      "metadata": {
        "id": "UwgJLIMcf9SB"
      },
      "id": "UwgJLIMcf9SB",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "4f5c2444",
      "metadata": {
        "id": "4f5c2444"
      },
      "source": [
        "## Visualizing the pickups and dropoffs"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# plot line chart showing the PU_count and DO_count over time\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Create the line chart\n",
        "plt.figure(figsize=(12, 6))\n",
        "plt.plot(PU_DO_counts.index, PU_DO_counts['PU_ct'], label='PU_ct')\n",
        "plt.plot(PU_DO_counts.index, PU_DO_counts['DO_ct'], label='DO_ct')\n",
        "\n",
        "# Customize the chart\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Count')\n",
        "plt.title('Pickups and Dropoffs Over Time')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "JGyrEtXZhnuH"
      },
      "id": "JGyrEtXZhnuH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "cbb1a6e3",
      "metadata": {
        "id": "cbb1a6e3"
      },
      "source": [
        "# Feature Information: Weather Data\n",
        "- From https://www.visualcrossing.com/weather-history/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "91178cea",
      "metadata": {
        "id": "91178cea"
      },
      "outputs": [],
      "source": [
        "# Loading the weather data\n",
        "df_weather = pd.read_csv('DC_weather_2024.csv')\n",
        "\n",
        "# Inspecting the dataframe\n",
        "df_weather.head()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checking info of columns\n",
        "df_weather.info()"
      ],
      "metadata": {
        "id": "d0I3EqWpi5zI"
      },
      "id": "d0I3EqWpi5zI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "94f6001e",
      "metadata": {
        "id": "94f6001e"
      },
      "source": [
        "## Drop variables of your choice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "82a937c9",
      "metadata": {
        "id": "82a937c9"
      },
      "outputs": [],
      "source": [
        "# Drop unnecessary variables\n",
        "df_weather=df_weather.drop(columns=['name', 'stations','description','sunrise','sunset','conditions','severerisk','preciptype','windgust'])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a28e9ce3",
      "metadata": {
        "id": "a28e9ce3"
      },
      "source": [
        "## Prepare X and y: Merge df_weather with PU_DO_counts"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert the 'datetime' column to datetime objects and extract the date\n",
        "df_weather['datetime'] = pd.to_datetime(df_weather['datetime'])\n",
        "df_weather['date'] = df_weather['datetime'].dt.date\n",
        "\n",
        "# Merge the two dataframes based on the 'date' column\n",
        "merged_df = pd.merge(PU_DO_counts, df_weather, on='date', how='left')\n",
        "\n",
        "# Display the merged dataframe\n",
        "merged_df"
      ],
      "metadata": {
        "id": "LceO3zBEq0-q"
      },
      "id": "LceO3zBEq0-q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3e5059bf",
      "metadata": {
        "id": "3e5059bf",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "sns.pairplot(merged_df[['PU_ct',\"temp\", \"precip\", \"windspeed\",\"uvindex\"]], kind=\"reg\",plot_kws=dict(scatter_kws=dict(s=2), line_kws = {'color':'black'})) # pairplot for PU_ct"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ef1734d",
      "metadata": {
        "id": "7ef1734d"
      },
      "source": [
        "# Prepare training and test data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0217869f",
      "metadata": {
        "id": "0217869f"
      },
      "outputs": [],
      "source": [
        "# we have two target variables: PU_ct and DO_ct\n",
        "y = merged_df[['PU_ct','DO_ct']]\n",
        "X = merged_df[['temp','precip','windspeed','uvindex','icon']]\n",
        "X"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Assignment 1: Regression Models**\n",
        "\n",
        "## Task 1: Train a linear regression model with a single feature ('temp') for PU_ct, and report the training and test MSE, respectively. [10 pts]"
      ],
      "metadata": {
        "id": "LarMT8RHBS9L"
      },
      "id": "LarMT8RHBS9L"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training and test data\n",
        "y = merged_df['PU_ct']\n",
        "X = merged_df[['temp']]\n",
        "X"
      ],
      "metadata": {
        "id": "xgC0m4wVKOFk"
      },
      "id": "xgC0m4wVKOFk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data: 60% train data and 40% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=200)"
      ],
      "metadata": {
        "id": "1hMvFb1AzuyI"
      },
      "id": "1hMvFb1AzuyI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the linear regression model:\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "pl3n5-m_Que5"
      },
      "id": "pl3n5-m_Que5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and calculating MSE:\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ],
      "metadata": {
        "id": "09tIAZKkJR8D"
      },
      "id": "09tIAZKkJR8D",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing MSE for Task 1 features: temp\n",
        "train_mse_task1 = train_mse\n",
        "test_mse_task1 = test_mse"
      ],
      "metadata": {
        "id": "u4X-eEZPUZqV"
      },
      "id": "u4X-eEZPUZqV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 2: Train a linear regression model with two feature ('temp' and 'precip') for PU_ct, and report the training and test MSE, respectively. [10 pts]"
      ],
      "metadata": {
        "id": "repvh2ZO52jz"
      },
      "id": "repvh2ZO52jz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training and test data\n",
        "y = merged_df['PU_ct']\n",
        "X = merged_df[['temp', 'precip']]\n",
        "X"
      ],
      "metadata": {
        "id": "CjMzUvqIMiDr"
      },
      "id": "CjMzUvqIMiDr",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data: 60% train data and 40% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=200)"
      ],
      "metadata": {
        "id": "LoZ8pof6HmHQ"
      },
      "id": "LoZ8pof6HmHQ",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the linear regression model:\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "kEDIR7Z7RFAl"
      },
      "id": "kEDIR7Z7RFAl",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and calculating MSE:\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ],
      "metadata": {
        "id": "8Sr0AfIEC0aS"
      },
      "id": "8Sr0AfIEC0aS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing MSE for Task 2 features: temp + precip\n",
        "train_mse_task2 = train_mse\n",
        "test_mse_task2 = test_mse"
      ],
      "metadata": {
        "id": "CrZQDvDFU2_F"
      },
      "id": "CrZQDvDFU2_F",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 3: Train a linear regression model with features ('temp','precip','windspeed') for PU_ct, and report the training and test MSE, respectively. [10 pts]"
      ],
      "metadata": {
        "id": "8dYwLPUQ7C_R"
      },
      "id": "8dYwLPUQ7C_R"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training and test data\n",
        "y = merged_df['PU_ct']\n",
        "X = merged_df[['temp', 'precip', 'windspeed']]\n",
        "X"
      ],
      "metadata": {
        "id": "BhtbRDQdMx5S"
      },
      "id": "BhtbRDQdMx5S",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data: 60% train data and 40% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=200)"
      ],
      "metadata": {
        "id": "SC3wTMKACkqX"
      },
      "id": "SC3wTMKACkqX",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the linear regression model:\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "4sUlVMZARO39"
      },
      "id": "4sUlVMZARO39",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and calculating MSE:\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ],
      "metadata": {
        "id": "7600tn2-Hn94"
      },
      "id": "7600tn2-Hn94",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing MSE for Task 3 featuers: temp + precip + windspeed\n",
        "train_mse_task3 = train_mse\n",
        "test_mse_task3 = test_mse"
      ],
      "metadata": {
        "id": "WmVrwUlJU7Aj"
      },
      "id": "WmVrwUlJU7Aj",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 4: Train a linear regression model with features ('temp','precip','windspeed','uvindex') for PU_ct, and report the training and test MSE, respectively. [10 pts]"
      ],
      "metadata": {
        "id": "njTBSAx37Ylz"
      },
      "id": "njTBSAx37Ylz"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training and test data\n",
        "y = merged_df['PU_ct']\n",
        "X = merged_df[['temp', 'precip', 'windspeed', 'uvindex']]\n",
        "X"
      ],
      "metadata": {
        "id": "b0YHAXBYM5t5"
      },
      "id": "b0YHAXBYM5t5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data: 60% train data and 40% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=200)"
      ],
      "metadata": {
        "id": "3F7wdq3fHpAq"
      },
      "id": "3F7wdq3fHpAq",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the linear regression model:\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "vtyR-ae-RX3X"
      },
      "id": "vtyR-ae-RX3X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and calculating MSE:\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ],
      "metadata": {
        "id": "nbSZGMM9CcV8"
      },
      "id": "nbSZGMM9CcV8",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing MSE for Task 4 features: temp + precip + windspeed + uvindex\n",
        "train_mse_task4 = train_mse\n",
        "test_mse_task4 = test_mse"
      ],
      "metadata": {
        "id": "LSVnY-ImVBmu"
      },
      "id": "LSVnY-ImVBmu",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 5: Train a linear regression model with features ('temp','precip','windspeed','uvindex','icon') for PU_ct, and report the training and test MSE, respectively. [10 pts]"
      ],
      "metadata": {
        "id": "NHEwVXx37tJT"
      },
      "id": "NHEwVXx37tJT"
    },
    {
      "cell_type": "code",
      "source": [
        "# Preparing the training and test data\n",
        "y = merged_df['PU_ct']\n",
        "X = pd.get_dummies(merged_df[['temp', 'precip', 'windspeed', 'uvindex', 'icon']], columns=['icon'], drop_first=True)\n",
        "X"
      ],
      "metadata": {
        "id": "-N3NIOegNIuT"
      },
      "id": "-N3NIOegNIuT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Splitting the data: 60% train data and 40% test data\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=200)"
      ],
      "metadata": {
        "id": "kiIn86TRCML5"
      },
      "id": "kiIn86TRCML5",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Training the linear regression model:\n",
        "model = LinearRegression()\n",
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "id": "642CNfT7Rcq-"
      },
      "id": "642CNfT7Rcq-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Predicting and calculating MSE:\n",
        "y_train_pred = model.predict(X_train)\n",
        "y_test_pred = model.predict(X_test)\n",
        "\n",
        "train_mse = mean_squared_error(y_train, y_train_pred)\n",
        "test_mse = mean_squared_error(y_test, y_test_pred)\n",
        "\n",
        "print(f\"Training MSE: {train_mse}\")\n",
        "print(f\"Test MSE: {test_mse}\")"
      ],
      "metadata": {
        "id": "fDCYheJ6HqTs"
      },
      "id": "fDCYheJ6HqTs",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Storing MSE for Task 5 features: temp + precip + windspeed + uvindex + icon_dummies\n",
        "train_mse_task5 = train_mse\n",
        "test_mse_task5 = test_mse"
      ],
      "metadata": {
        "id": "08cDv7JRVFaW"
      },
      "id": "08cDv7JRVFaW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 6: Based on the previous results, plot the changes in training and test MSEs as more features are added to the linear regression model. [10 pts]"
      ],
      "metadata": {
        "id": "Ksx5Iahn9Byy"
      },
      "id": "Ksx5Iahn9Byy"
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "yA-TJVUqSfpW"
      },
      "id": "yA-TJVUqSfpW",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# MSE values from the Tasks 1â€“5\n",
        "mse_data = {\n",
        "    'Features': [\n",
        "        'temp',\n",
        "        'temp,precip',\n",
        "        'temp,precip,windspeed',\n",
        "        'temp,precip,windspeed,uvindex',\n",
        "        'temp,precip,windspeed,uvindex,icon_dummies'\n",
        "    ],\n",
        "    'Train_MSE': [train_mse_task1, train_mse_task2, train_mse_task3, train_mse_task4, train_mse_task5],\n",
        "    'Test_MSE': [test_mse_task1, test_mse_task2, test_mse_task3, test_mse_task4, test_mse_task5]\n",
        "}\n",
        "# DataFrame storing the MSE values\n",
        "mse_df = pd.DataFrame(mse_data)"
      ],
      "metadata": {
        "id": "3W01yX5QSgkS"
      },
      "id": "3W01yX5QSgkS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plotting the train and test MSE values\n",
        "plt.figure(figsize=(8, 5))\n",
        "plt.plot(mse_df['Features'], mse_df['Train_MSE'], label='Train MSE', marker='o')\n",
        "plt.plot(mse_df['Features'], mse_df['Test_MSE'], label='Test MSE', marker='s')\n",
        "plt.xlabel('Features')\n",
        "plt.ylabel('MSE')\n",
        "plt.title('Training and Test MSE vs. Features')\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.xticks(rotation=60)  # Rotating x-axis labels for better readability\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VwikMdSzB_vg"
      },
      "id": "VwikMdSzB_vg",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 7: Based on the above plot, identify the best combination of features for PU_ct prediction in linear regression. [10 pts]"
      ],
      "metadata": {
        "id": "CdjgaV42CkBx"
      },
      "id": "CdjgaV42CkBx"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ynTS-LY3HulS"
      },
      "id": "ynTS-LY3HulS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Task 8: Conduct Task 1-7 again for DO_ct prediction. [30 pts]"
      ],
      "metadata": {
        "id": "3FSL193gC8d_"
      },
      "id": "3FSL193gC8d_"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "9cW8owlfHS8X"
      },
      "id": "9cW8owlfHS8X",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Reference\n",
        "##### <font color=\"red\">\"DeepSeek AI (Version 1.0, developed by DeepSeek AI, accessed January 28, 2025)\" was consulted during the research process.</font>\n"
      ],
      "metadata": {
        "id": "w5iPkA1LchMG"
      },
      "id": "w5iPkA1LchMG"
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "whDb_4hKclbR"
      },
      "id": "whDb_4hKclbR",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}